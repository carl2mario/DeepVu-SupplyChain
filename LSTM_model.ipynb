{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model for price prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Assumptions of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model used : encoder decoder made of GRU cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported tensorflow 1.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf  \n",
    "import utils\n",
    "print('Imported tensorflow', tf.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('metals_daily_train.csv')\n",
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>p0</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>f000_open</th>\n",
       "      <th>f000_high</th>\n",
       "      <th>f000_low</th>\n",
       "      <th>f000_settle</th>\n",
       "      <th>f001_open</th>\n",
       "      <th>f001_high</th>\n",
       "      <th>...</th>\n",
       "      <th>f136_open</th>\n",
       "      <th>f136_high</th>\n",
       "      <th>f136_low</th>\n",
       "      <th>f136_settle</th>\n",
       "      <th>f137_open</th>\n",
       "      <th>f137_high</th>\n",
       "      <th>f137_low</th>\n",
       "      <th>f137_settle</th>\n",
       "      <th>week</th>\n",
       "      <th>week_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>20081201</td>\n",
       "      <td>444.511058</td>\n",
       "      <td>457.032497</td>\n",
       "      <td>457.032497</td>\n",
       "      <td>53.08</td>\n",
       "      <td>56.33</td>\n",
       "      <td>52.62</td>\n",
       "      <td>56.29</td>\n",
       "      <td>49.11</td>\n",
       "      <td>52.15</td>\n",
       "      <td>...</td>\n",
       "      <td>9420.0</td>\n",
       "      <td>9680.0</td>\n",
       "      <td>9315.0</td>\n",
       "      <td>9540.0</td>\n",
       "      <td>9520.0</td>\n",
       "      <td>9800.0</td>\n",
       "      <td>9495.0</td>\n",
       "      <td>9650.0</td>\n",
       "      <td>2030</td>\n",
       "      <td>20081201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>20081202</td>\n",
       "      <td>446.908899</td>\n",
       "      <td>465.530103</td>\n",
       "      <td>459.323035</td>\n",
       "      <td>55.99</td>\n",
       "      <td>56.29</td>\n",
       "      <td>54.68</td>\n",
       "      <td>55.30</td>\n",
       "      <td>51.80</td>\n",
       "      <td>52.24</td>\n",
       "      <td>...</td>\n",
       "      <td>9480.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>9430.0</td>\n",
       "      <td>9510.0</td>\n",
       "      <td>9640.0</td>\n",
       "      <td>9730.0</td>\n",
       "      <td>9560.0</td>\n",
       "      <td>9630.0</td>\n",
       "      <td>2030</td>\n",
       "      <td>20081201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>20081203</td>\n",
       "      <td>453.484820</td>\n",
       "      <td>482.060575</td>\n",
       "      <td>459.696940</td>\n",
       "      <td>56.50</td>\n",
       "      <td>56.72</td>\n",
       "      <td>54.65</td>\n",
       "      <td>55.21</td>\n",
       "      <td>53.01</td>\n",
       "      <td>53.02</td>\n",
       "      <td>...</td>\n",
       "      <td>9495.0</td>\n",
       "      <td>9580.0</td>\n",
       "      <td>9400.0</td>\n",
       "      <td>9500.0</td>\n",
       "      <td>9530.0</td>\n",
       "      <td>9690.0</td>\n",
       "      <td>9505.0</td>\n",
       "      <td>9590.0</td>\n",
       "      <td>2030</td>\n",
       "      <td>20081201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>20081204</td>\n",
       "      <td>447.532919</td>\n",
       "      <td>472.395859</td>\n",
       "      <td>459.964389</td>\n",
       "      <td>55.50</td>\n",
       "      <td>57.81</td>\n",
       "      <td>54.88</td>\n",
       "      <td>57.62</td>\n",
       "      <td>51.75</td>\n",
       "      <td>54.42</td>\n",
       "      <td>...</td>\n",
       "      <td>9485.0</td>\n",
       "      <td>9485.0</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>9145.0</td>\n",
       "      <td>9400.0</td>\n",
       "      <td>9445.0</td>\n",
       "      <td>9205.0</td>\n",
       "      <td>9225.0</td>\n",
       "      <td>2030</td>\n",
       "      <td>20081201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>20081205</td>\n",
       "      <td>447.084228</td>\n",
       "      <td>471.922241</td>\n",
       "      <td>459.503235</td>\n",
       "      <td>58.50</td>\n",
       "      <td>60.00</td>\n",
       "      <td>56.63</td>\n",
       "      <td>56.75</td>\n",
       "      <td>54.70</td>\n",
       "      <td>56.18</td>\n",
       "      <td>...</td>\n",
       "      <td>8710.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>8595.0</td>\n",
       "      <td>8665.0</td>\n",
       "      <td>8885.0</td>\n",
       "      <td>8940.0</td>\n",
       "      <td>8670.0</td>\n",
       "      <td>8715.0</td>\n",
       "      <td>2030</td>\n",
       "      <td>20081201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 558 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date          p0          p1          p2  f000_open  f000_high  \\\n",
       "109  20081201  444.511058  457.032497  457.032497      53.08      56.33   \n",
       "110  20081202  446.908899  465.530103  459.323035      55.99      56.29   \n",
       "111  20081203  453.484820  482.060575  459.696940      56.50      56.72   \n",
       "112  20081204  447.532919  472.395859  459.964389      55.50      57.81   \n",
       "113  20081205  447.084228  471.922241  459.503235      58.50      60.00   \n",
       "\n",
       "     f000_low  f000_settle  f001_open  f001_high    ...      f136_open  \\\n",
       "109     52.62        56.29      49.11      52.15    ...         9420.0   \n",
       "110     54.68        55.30      51.80      52.24    ...         9480.0   \n",
       "111     54.65        55.21      53.01      53.02    ...         9495.0   \n",
       "112     54.88        57.62      51.75      54.42    ...         9485.0   \n",
       "113     56.63        56.75      54.70      56.18    ...         8710.0   \n",
       "\n",
       "     f136_high  f136_low  f136_settle  f137_open  f137_high  f137_low  \\\n",
       "109     9680.0    9315.0       9540.0     9520.0     9800.0    9495.0   \n",
       "110     9600.0    9430.0       9510.0     9640.0     9730.0    9560.0   \n",
       "111     9580.0    9400.0       9500.0     9530.0     9690.0    9505.0   \n",
       "112     9485.0    9120.0       9145.0     9400.0     9445.0    9205.0   \n",
       "113     9000.0    8595.0       8665.0     8885.0     8940.0    8670.0   \n",
       "\n",
       "     f137_settle  week  week_date  \n",
       "109       9650.0  2030   20081201  \n",
       "110       9630.0  2030   20081201  \n",
       "111       9590.0  2030   20081201  \n",
       "112       9225.0  2030   20081201  \n",
       "113       8715.0  2030   20081201  \n",
       "\n",
       "[5 rows x 558 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p1 = df[\"p1\"].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Seq2Seq with GRU cells model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sample(df, batch_size, input_seq_len, output_seq_len, random_state=None):\n",
    "    \"\"\"Get a batch from the dataframe. \n",
    "    \n",
    "    Each batch contains batch_size sequences. \n",
    "    Each sequences is made of input_seq_len values and the follwing output_seq_len \n",
    "    values of the time series.\n",
    "    \"\"\"\n",
    "    X_batch = []\n",
    "    y_batch = []\n",
    "    for _ in range(batch_size):\n",
    "        n = df.shape[0]\n",
    "        r = np.random.randint(0, n-output_seq_len-input_seq_len)\n",
    "        X_batch.append(df[r:r+input_seq_len].values.reshape((-1, 1)))\n",
    "        y_batch.append(df[r+input_seq_len:r+input_seq_len+output_seq_len].values.reshape((-1, 1)))\n",
    "    X_batch = np.array(X_batch)\n",
    "    X_batch = np.array(X_batch).transpose((1, 0, 2))\n",
    "    y_batch = np.array(y_batch).transpose((1, 0, 2))\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load paths to TF seq2seq model and recurrent cells to be used in this project\n",
    "tf.nn.seq2seq = tf.contrib.legacy_seq2seq\n",
    "tf.nn.rnn_cell = tf.contrib.rnn \n",
    "tf.nn.rnn_cell.GRUCell = tf.contrib.rnn.GRUCell # Useful for learning long-range dependencies in sequences\n",
    "\n",
    "# Data shape parameters\n",
    "batch_size = 15 # How many time series to train on before updating model's weight parameters\n",
    "output_seq_len = 6 # How many days to predict into the future\n",
    "input_seq_len = 25 # How many days to train on in the past\n",
    "\n",
    "# Internal neural network parameters\n",
    "input_dim = output_dim = 1 # Univariate time series (predicting future values based on stream of historical values)\n",
    "hidden_dim = 30  # Number of neurons in each recurrent unit \n",
    "num_layers = 2  # Number of stacked recurrent cells (number of recurrent layers)\n",
    "\n",
    "# Optimizer parameters\n",
    "learning_rate = 0.005  # Small lr helps not to diverge during training. \n",
    "epochs =  1000 #1000  # How many times we perform a training step (how many times we show a batch)\n",
    "lr_decay = 0.9  # default: 0.9 . Simulated annealing.\n",
    "momentum = 0.2  # default: 0.0 . Momentum technique in weights update\n",
    "lambda_l2_reg = 0.003  # L2 regularization of weights - reduces overfitting\n",
    "\n",
    "# Declare which airline-airport time series will be used for testing\n",
    "#airline_airports = [('AA', 'DFW'), ('DL', 'ATL'), ('UA', 'ORD')]\n",
    "# Exclude them from training phase\n",
    "#excluded = map('-'.join, airline_airports)\n",
    "# Allow fetching of same three samples during validation\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset any existing graph, close any previous session, discard old variables, and start fresh\n",
    "tf.reset_default_graph()\n",
    "if 'sess' in globals():\n",
    "    sess.close()\n",
    "sess = tf.InteractiveSession()\n",
    "tf.set_random_seed(random_state)\n",
    "\n",
    "with tf.variable_scope('Seq2Seq'):\n",
    "    # Input values to encoder RNN\n",
    "    encoder_inputs = [tf.placeholder(tf.float32, shape=(None, input_dim), \n",
    "                     name=\"encoder_input_{}\".format(t)) for t in range(input_seq_len)]\n",
    "    \n",
    "    # Target values for decoder RNN\n",
    "    decoder_targets = [tf.placeholder(tf.float32, shape=(None, output_dim), \n",
    "                       name=\"decoder_target_{}\".format(t)) for t in range(output_seq_len)]\n",
    "    \n",
    "    # Feed final n encoder inputs into the decoder RNN, where n = output_seq_len\n",
    "    # \"GO\", represented by 0, starts the decoder\n",
    "    decoder_inputs = [tf.zeros_like(encoder_inputs[0], dtype=np.float32, name=\"GO\")] +\\\n",
    "                      encoder_inputs[-(output_seq_len - 1):]\n",
    "    \n",
    "    # Stack hidden recurrent layers\n",
    "    cells = list()\n",
    "    for i in range(num_layers):\n",
    "        with tf.variable_scope('RNN_' + str(i)):\n",
    "            cells.append(tf.nn.rnn_cell.GRUCell(hidden_dim))\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "    \n",
    "    # Pass encoder and decoder inputs through model, retrieving output from the decoder at each prediction step\n",
    "    decoder_outputs, decoder_state = tf.nn.seq2seq.basic_rnn_seq2seq(encoder_inputs, decoder_inputs, cell)\n",
    "    \n",
    "    # Squeeze decoder output into a single value, representing the forecast at that point in the sequence\n",
    "    W_out = tf.Variable(tf.truncated_normal([hidden_dim, output_dim], seed=random_state)) # Output weight matrix\n",
    "    b_out = tf.Variable(tf.truncated_normal([output_dim], seed=random_state)) # Output bias\n",
    "    \n",
    "    # Apply a trainable, constant linear transformation to final outputs\n",
    "    output_scale_factor = tf.Variable(1.0, name=\"Output_Scale_Factor\")\n",
    "    reshaped_outputs = [output_scale_factor * (tf.matmul(i, W_out) + b_out) for i in decoder_outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('Loss'):\n",
    "    # Compute L2 loss for output at each time step: \n",
    "    # https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss\n",
    "    output_loss = 0\n",
    "    for _y, _Y in zip(reshaped_outputs, decoder_targets):\n",
    "        output_loss += tf.reduce_mean(tf.nn.l2_loss(_y - _Y))\n",
    "    # Penalize model complexity with L2 regularization\n",
    "    reg_loss = 0\n",
    "    for tf_var in tf.trainable_variables():\n",
    "        if not (\"Bias\" in tf_var.name or \"Output_\" in tf_var.name):\n",
    "            reg_loss += tf.reduce_mean(tf.nn.l2_loss(tf_var))\n",
    "    # Add regularization term to loss function        \n",
    "    loss = output_loss + lambda_l2_reg * reg_loss\n",
    "    \n",
    "with tf.variable_scope('Optimizer'):\n",
    "    # Search for minimum of loss function with RMSProp:\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate, decay=lr_decay, momentum=momentum, centered=False)\n",
    "    train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(df, batch_size, input_seq_len, output_seq_len):\n",
    "    \"\"\"\n",
    "    Trains session model, attempting to optimize internal weight parameters\n",
    "    to accurately predict the number of steps into future given by output_seq_len\n",
    "    \n",
    "    @df: DataFrame to sample random time series from\n",
    "    @batch_size: How many time series to sample at a time\n",
    "    @input_seq_len: How many months before for prediction (training)\n",
    "    @output_seq_len: How many months to reserve for prediction (training target)\n",
    "    \"\"\"\n",
    "    X_train, y_train = fetch_sample(df=df, \n",
    "                                    batch_size=batch_size, \n",
    "                                    input_seq_len=input_seq_len, \n",
    "                                    output_seq_len=output_seq_len)\n",
    "    feed_dict = {encoder_inputs[t]: X_train[t] for t in range(len(encoder_inputs))}\n",
    "    feed_dict.update({decoder_targets[t]: y_train[t] for t in range(len(decoder_targets))})\n",
    "    train_loss = sess.run([train_op, loss], feed_dict)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch(df, input_seq_len, output_seq_len, random_state=None):\n",
    "    \"\"\"\n",
    "    Tests session model on a batch of random time series drawn from one of the metrics DataFrames.\n",
    "    All passed parameters should be same as those used during training.\n",
    "    \n",
    "    @df: DataFrame to sample random time series from\n",
    "    @batch_size: How many time series to sample at a time\n",
    "    @input_seq_len: How many months before for prediction (training)\n",
    "    @output_seq_len: How many months to set aside for prediction (training target)\n",
    "    @random_state: Controls reproducible output\n",
    "    \"\"\"\n",
    "    X_test, y_test = fetch_sample(df=df, \n",
    "                                  batch_size=1, \n",
    "                                  input_seq_len=input_seq_len, \n",
    "                                  output_seq_len=output_seq_len,\n",
    "                                  random_state=random_state)\n",
    "    feed_dict = {encoder_inputs[t]: X_test[t] for t in range(len(encoder_inputs))}\n",
    "    feed_dict.update({decoder_targets[t]: y_test[t] for t in range(len(decoder_targets))})\n",
    "    test_loss = sess.run([train_op, loss], feed_dict)\n",
    "    return test_loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0/1000 \ttrain loss: 10819847.0 \tdev loss: 392211.65625\n",
      "Step 10/1000 \ttrain loss: 9662343.0 \tdev loss: 350875.71875\n",
      "Step 20/1000 \ttrain loss: 10126165.0 \tdev loss: 913758.25\n",
      "Step 30/1000 \ttrain loss: 8606787.0 \tdev loss: 709574.875\n",
      "Step 40/1000 \ttrain loss: 10627357.0 \tdev loss: 293439.1875\n",
      "Step 50/1000 \ttrain loss: 9428605.0 \tdev loss: 413006.96875\n",
      "Step 60/1000 \ttrain loss: 8060102.5 \tdev loss: 427937.46875\n",
      "Step 70/1000 \ttrain loss: 9481728.0 \tdev loss: 197784.609375\n",
      "Step 80/1000 \ttrain loss: 7847341.0 \tdev loss: 604741.4375\n",
      "Step 90/1000 \ttrain loss: 8250204.0 \tdev loss: 404617.375\n",
      "Step 100/1000 \ttrain loss: 9400995.0 \tdev loss: 569758.25\n",
      "Step 110/1000 \ttrain loss: 7606292.5 \tdev loss: 776747.5625\n",
      "Step 120/1000 \ttrain loss: 8650230.0 \tdev loss: 797670.3125\n",
      "Step 130/1000 \ttrain loss: 8409444.0 \tdev loss: 673360.8125\n",
      "Step 140/1000 \ttrain loss: 7653629.0 \tdev loss: 365980.8125\n",
      "Step 150/1000 \ttrain loss: 7712994.5 \tdev loss: 502598.15625\n",
      "Step 160/1000 \ttrain loss: 6478265.0 \tdev loss: 76430.1796875\n",
      "Step 170/1000 \ttrain loss: 6167637.0 \tdev loss: 279579.0\n",
      "Step 180/1000 \ttrain loss: 6631638.0 \tdev loss: 417772.0625\n",
      "Step 190/1000 \ttrain loss: 6738390.0 \tdev loss: 160051.296875\n",
      "Step 200/1000 \ttrain loss: 5177947.5 \tdev loss: 126297.140625\n",
      "Step 210/1000 \ttrain loss: 4886809.0 \tdev loss: 521990.96875\n",
      "Step 220/1000 \ttrain loss: 3997854.25 \tdev loss: 93214.921875\n",
      "Step 230/1000 \ttrain loss: 5846723.0 \tdev loss: 81357.2578125\n",
      "Step 240/1000 \ttrain loss: 5333470.0 \tdev loss: 88517.484375\n",
      "Step 250/1000 \ttrain loss: 3790884.0 \tdev loss: 329477.0\n",
      "Step 260/1000 \ttrain loss: 3309350.75 \tdev loss: 158182.828125\n",
      "Step 270/1000 \ttrain loss: 4087395.75 \tdev loss: 218645.796875\n",
      "Step 280/1000 \ttrain loss: 3908699.25 \tdev loss: 35969.86328125\n",
      "Step 290/1000 \ttrain loss: 3781413.0 \tdev loss: 168972.265625\n",
      "Step 300/1000 \ttrain loss: 3359897.0 \tdev loss: 339910.65625\n",
      "Step 310/1000 \ttrain loss: 2612058.0 \tdev loss: 276040.40625\n",
      "Step 320/1000 \ttrain loss: 2183145.5 \tdev loss: 172366.875\n",
      "Step 330/1000 \ttrain loss: 2202715.0 \tdev loss: 126772.390625\n",
      "Step 340/1000 \ttrain loss: 2019781.75 \tdev loss: 230789.171875\n",
      "Step 350/1000 \ttrain loss: 1951728.75 \tdev loss: 86958.46875\n",
      "Step 360/1000 \ttrain loss: 1883988.75 \tdev loss: 300567.25\n",
      "Step 370/1000 \ttrain loss: 1139084.0 \tdev loss: 84316.2421875\n",
      "Step 380/1000 \ttrain loss: 1466362.0 \tdev loss: 43257.39453125\n",
      "Step 390/1000 \ttrain loss: 1258863.625 \tdev loss: 11856.5517578125\n",
      "Step 400/1000 \ttrain loss: 1322440.25 \tdev loss: 75049.6640625\n",
      "Step 410/1000 \ttrain loss: 921470.375 \tdev loss: 163644.984375\n",
      "Step 420/1000 \ttrain loss: 660697.625 \tdev loss: 157761.359375\n",
      "Step 430/1000 \ttrain loss: 945982.6875 \tdev loss: 89731.1328125\n",
      "Step 440/1000 \ttrain loss: 377042.59375 \tdev loss: 19050.951171875\n",
      "Step 450/1000 \ttrain loss: 585322.75 \tdev loss: 116521.3515625\n",
      "Step 460/1000 \ttrain loss: 455075.28125 \tdev loss: 13017.0029296875\n",
      "Step 470/1000 \ttrain loss: 402673.6875 \tdev loss: 35693.37890625\n",
      "Step 480/1000 \ttrain loss: 261945.265625 \tdev loss: 4684.76416015625\n",
      "Step 490/1000 \ttrain loss: 262099.578125 \tdev loss: 45.58145523071289\n",
      "Step 500/1000 \ttrain loss: 473256.5625 \tdev loss: 61221.6640625\n",
      "Step 510/1000 \ttrain loss: 222674.96875 \tdev loss: 69485.5859375\n",
      "Step 520/1000 \ttrain loss: 639786.25 \tdev loss: 10505.943359375\n",
      "Step 530/1000 \ttrain loss: 466218.34375 \tdev loss: 92411.359375\n",
      "Step 540/1000 \ttrain loss: 430810.9375 \tdev loss: 3866.454833984375\n",
      "Step 550/1000 \ttrain loss: 511118.375 \tdev loss: 21553.97265625\n",
      "Step 560/1000 \ttrain loss: 582437.4375 \tdev loss: 32081.671875\n",
      "Step 570/1000 \ttrain loss: 368163.59375 \tdev loss: 13367.150390625\n",
      "Step 580/1000 \ttrain loss: 444047.75 \tdev loss: 63350.0625\n",
      "Step 590/1000 \ttrain loss: 284438.03125 \tdev loss: 26850.572265625\n",
      "Step 600/1000 \ttrain loss: 644398.5625 \tdev loss: 60449.83984375\n",
      "Step 610/1000 \ttrain loss: 645161.625 \tdev loss: 1876.904296875\n",
      "Step 620/1000 \ttrain loss: 370401.90625 \tdev loss: 96567.890625\n",
      "Step 630/1000 \ttrain loss: 553725.9375 \tdev loss: 1290.0478515625\n",
      "Step 640/1000 \ttrain loss: 280432.78125 \tdev loss: 19960.75\n",
      "Step 650/1000 \ttrain loss: 490052.96875 \tdev loss: 156.58819580078125\n",
      "Step 660/1000 \ttrain loss: 324592.15625 \tdev loss: 2593.595458984375\n",
      "Step 670/1000 \ttrain loss: 366368.40625 \tdev loss: 28663.134765625\n",
      "Step 680/1000 \ttrain loss: 421924.6875 \tdev loss: 27557.48828125\n",
      "Step 690/1000 \ttrain loss: 373587.15625 \tdev loss: 15238.1845703125\n",
      "Step 700/1000 \ttrain loss: 189922.671875 \tdev loss: 9043.244140625\n",
      "Step 710/1000 \ttrain loss: 563080.0 \tdev loss: 12391.7333984375\n",
      "Step 720/1000 \ttrain loss: 343416.3125 \tdev loss: 105720.203125\n",
      "Step 730/1000 \ttrain loss: 253096.953125 \tdev loss: 20491.97265625\n",
      "Step 740/1000 \ttrain loss: 352485.4375 \tdev loss: 5533.9345703125\n",
      "Step 750/1000 \ttrain loss: 442038.3125 \tdev loss: 11000.365234375\n",
      "Step 760/1000 \ttrain loss: 144622.046875 \tdev loss: 2156.197998046875\n",
      "Step 770/1000 \ttrain loss: 652475.1875 \tdev loss: 1896.5565185546875\n",
      "Step 780/1000 \ttrain loss: 362651.15625 \tdev loss: 1579.01220703125\n",
      "Step 790/1000 \ttrain loss: 80458.1015625 \tdev loss: 14143.4853515625\n",
      "Step 800/1000 \ttrain loss: 302248.6875 \tdev loss: 2243.00927734375\n",
      "Step 810/1000 \ttrain loss: 200509.828125 \tdev loss: 3211.058349609375\n",
      "Step 820/1000 \ttrain loss: 217638.796875 \tdev loss: 897.3410034179688\n",
      "Step 830/1000 \ttrain loss: 236526.234375 \tdev loss: 29434.111328125\n",
      "Step 840/1000 \ttrain loss: 477532.125 \tdev loss: 6378.50244140625\n",
      "Step 850/1000 \ttrain loss: 151856.65625 \tdev loss: 11768.2021484375\n",
      "Step 860/1000 \ttrain loss: 161776.46875 \tdev loss: 34332.6796875\n",
      "Step 870/1000 \ttrain loss: 367991.5625 \tdev loss: 44605.28125\n",
      "Step 880/1000 \ttrain loss: 329468.5625 \tdev loss: 4967.64990234375\n",
      "Step 890/1000 \ttrain loss: 252412.5 \tdev loss: 26027.193359375\n",
      "Step 900/1000 \ttrain loss: 372900.25 \tdev loss: 595.4185791015625\n",
      "Step 910/1000 \ttrain loss: 142641.03125 \tdev loss: 9462.73828125\n",
      "Step 920/1000 \ttrain loss: 235894.03125 \tdev loss: 504.5956115722656\n",
      "Step 930/1000 \ttrain loss: 258363.21875 \tdev loss: 97783.46875\n",
      "Step 940/1000 \ttrain loss: 258930.78125 \tdev loss: 8972.2421875\n",
      "Step 950/1000 \ttrain loss: 126328.5078125 \tdev loss: 44732.80078125\n",
      "Step 960/1000 \ttrain loss: 27904.029296875 \tdev loss: 13261.7431640625\n",
      "Step 970/1000 \ttrain loss: 160249.015625 \tdev loss: 16306.4736328125\n",
      "Step 980/1000 \ttrain loss: 94952.6640625 \tdev loss: 3475.94384765625\n",
      "Step 990/1000 \ttrain loss: 176849.109375 \tdev loss: 12697.1337890625\n",
      "Step 1000/1000 \ttrain loss: 137747.484375 \tdev loss: 617.8547973632812\n"
     ]
    }
   ],
   "source": [
    "# Reset variables and run passengers training ops\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for t in range(epochs + 1):\n",
    "    train_loss = train_batch(df=df_p1, batch_size=batch_size, input_seq_len=input_seq_len, output_seq_len=output_seq_len)\n",
    "    # Taking the dev_loss on the same random samples serves as a validation run every 100 training runs\n",
    "    if t % 10 == 0:\n",
    "        dev_loss = test_batch(df=df_p1, input_seq_len=input_seq_len, output_seq_len=output_seq_len)\n",
    "        print(\"Step {0}/{1} \\ttrain loss: {2} \\tdev loss: {3}\".format(t, epochs, train_loss[1], dev_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 534.925354]], dtype=float32),\n",
       " array([[ 534.95220947]], dtype=float32),\n",
       " array([[ 534.97644043]], dtype=float32),\n",
       " array([[ 535.]], dtype=float32),\n",
       " array([[ 535.02288818]], dtype=float32),\n",
       " array([[ 535.04522705]], dtype=float32)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = fetch_sample(df_p1, 1, input_seq_len, output_seq_len, random_state=random_state)\n",
    "feed_dict = {encoder_inputs[t]: X_test[t] for t in range(len(encoder_inputs))}\n",
    "feed_dict.update({decoder_targets[t]: y_test[t] for t in range(len(decoder_targets))})\n",
    "res = sess.run([reshaped_outputs], feed_dict=feed_dict)[0]\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18afbf0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def viz_prediction(X_test, y_test, batch_sample_nb):\n",
    "    assert (batch_sample_nb < batch_size) & (batch_sample_nb > 0)\n",
    "    X_test, y_test = fetch_sample(df_p1, batch_size, input_seq_len, output_seq_len)\n",
    "    feed_dict = {encoder_inputs[t]: X_test[t] for t in range(len(encoder_inputs))}\n",
    "    feed_dict.update({decoder_targets[t]: y_test[t] for t in range(len(decoder_targets))})\n",
    "    res = sess.run([reshaped_outputs], feed_dict=feed_dict)[0]\n",
    "    res = np.array(res)\n",
    "    # shape: (output_seq_len, batch_size, input_dim)\n",
    "    res.transpose((1,0,2))\n",
    "    X_plot = list(X_test[:, batch_sample_nb, :].flatten())\n",
    "    y_plot = list(y_test[:, batch_sample_nb, :].flatten())\n",
    "    y_pred = list(res[:, batch_sample_nb].flatten())\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(X_plot + y_plot, label='actual')\n",
    "    plt.plot(X_plot + y_pred, label='prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "viz_prediction(X_test, y_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
