{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_correlated(df, nb_features, threshold, correlation_method=3):\n",
    "    \"\"\"Select top 20 correlated features from DataFrame\"\"\"\n",
    "    # select settle prices only\n",
    "    keep_col = [0, 1] + list(range(5, 557, 4))\n",
    "    selected_columns = df.iloc[:, keep_col].columns\n",
    "    \n",
    "    # compute correlation matrix\n",
    "    df_cor = pd.DataFrame(columns=['pearson', 'spearman', 'kendall'])\n",
    "    df_cor['pearson'] = df[selected_columns].corr(method='pearson')['p1']\n",
    "    df_cor['spearman'] = df[selected_columns].corr(method='spearman')['p1']\n",
    "    df_cor['kendall'] = df[selected_columns].corr(method='kendall')['p1']\n",
    "    df_cor['score'] = (abs(df_cor['pearson']) + abs(df_cor['spearman']) + abs(df_cor['kendall'])) / 3\n",
    "    \n",
    "    # sort depending on the correlation_method \n",
    "    col = df_cor.columns[correlation_method]\n",
    "    df_cor_sorted = df_cor.sort_values(by=col, ascending=False)[col]    \n",
    "    \n",
    "    # retrieve the top nb_features correlated with p1\n",
    "    selected_features = df_cor_sorted.index[:nb_features] \n",
    "    \n",
    "    # eliminate features that are too correlated to each other\n",
    "    df_cor_count = df_cor.loc[selected_features].copy()\n",
    "    df_cor_count[df_cor_count < threshold] = 0\n",
    "    df_cor_count[df_cor_count >= threshold] = 1\n",
    "    df_cor_count = df_cor_count.sum(axis=1)\n",
    "    df_cor_count = df_cor_count[df_cor_count > 0]\n",
    "    df_cor_count = df_cor_count.sort_values(ascending=False)\n",
    "    \n",
    "    # keep 20 at most\n",
    "    limit = min(20, len(df_cor_count))\n",
    "    selected_features = df_cor_count.index[:limit]\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "def pca_selection(df, n=20):\n",
    "    \"Perform PCA to reduce then number of features\"\n",
    "    # first scale data\n",
    "    X = df.values\n",
    "    scaler = StandardScaler()\n",
    "    X_sc = scaler.fit_transform(X)\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components=n)\n",
    "    X_pca = pca.fit_transform(X_sc)\n",
    "    \n",
    "    return pd.DataFrame(X_pca, index=df.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
